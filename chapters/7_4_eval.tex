\chapter{Experimental Evaluation}
\label{chap:eval}

\section{Introduction}
\label{sec:eval-intro}

The WASI \acrshort{i2c} proposal's progression to Phase 3 requires demonstrated compatibility with embedded device constraints as defined by the portability criteria Table~\ref{tab:portability_criteria}. These specify resource-constrained platforms including the Nucleo F412ZG with only \SIi{256}{\kilo\byte} SRAM and \SIi{1}{\mega\byte} Flash memory, representing the minimal viable embedded deployment target. For WebAssembly to succeed in embedded \acrshort{i2c} applications, implementations must operate efficiently within these stringent memory and performance constraints.

This chapter presents a comprehensive experimental evaluation of the \acrshort{i2c} WASI interface implementations developed for the WAMR and Wasmtime runtimes, with particular emphasis on their \textbf{performance characteristics} and \textbf{resource utilization} in embedded deployment scenarios. It encompasses \textbf{timing analysis} across multiple execution phases and comprehensive \textbf{memory profiling} to track allocation patterns. This data is then used for statistical analysis to ensure reliable and reproducible results. By systematically measuring \textbf{runtime setup overhead}, \textbf{execution latency}, and \textbf{memory consumption}, this experimental evaluation provides quantitative insights into the use of the WASI \acrshort{i2c} interface in these constrained environments.

WAMR's results are particularly critical because it represents the primary runtime architecture capable of meeting these embedded constraints. Unlike feature-rich runtimes designed for server environments, WAMR's embedded-optimized architecture directly targets the resource limitations specified in the portability criteria. If WAMR cannot demonstrate acceptable performance and memory efficiency, the Preview 1 approach --- and by extension, the entire embedded WebAssembly \acrshort{i2c} concept --- would lack a viable deployment foundation for resource-constrained systems.

\section{Evaluation Setup}
\label{sec:eval-methodology}

\subsection{The Ping-Pong Routine: Comprehensive System Validation}
\label{subsec:ping-pong-routine}

The Ping-Pong routine represents more than a simple \acrshort{i2c} communication test; it serves as a comprehensive validation of the entire WebAssembly \acrshort{i2c} implementation, exercising every critical component of the system in a minimal, reproducible manner. Importantly, the routine encompasses the complete resource lifecycle, including resource creation, usage, and destruction.

\begin{listing}[H]
    \begin{minted}[breaklines]{rust}
        fn complete_pingpong_sequence() -> Result<(), ErrorCode> {
            // Phase 1: Resource Creation and Acquisition
            let device = I2cResource::new();  // Triggers host_open() call, handle allocation
            
            // Phase 2: Write Operation with Memory Transfer
            let message = [0x68, 0x65, 0x6c, 0x6c, 0x6f]; // ASCII "hello"
            device.write(0x09, &message)?;  // Triggers host_write() call, Host/guest boundary crossing
            
            // Phase 3: Read Operation with Buffer Allocation and Return
            let response = device.read(0x09, 5)?;  // Triggers host_read() call, Guest-managed memory allocation and data transfer
            
            Ok(())
            // Phase 4: Automatic Resource Cleanup (via Drop trait)
        }  // device.drop() called here, triggering host_close() and handle deallocation
    \end{minted}
    \caption{Complete ping-pong implementation demonstrating resource creation, bidirectional \acrshort{i2c} communication, and automatic cleanup within a single operation}
    \label{lst:complete-pingpong}
\end{listing}

The ping-pong routine exercises the following critical system components:

\textbf{Resource Lifecycle Management}: The creation of an \texttt{I2cResource} instance triggers the complete resource acquisition sequence, including host function invocation, handle allocation, permission assignment, and registration in the permission management system. The automatic cleanup through Rust's Drop trait ensures proper resource deallocation and prevents handle leaks.

\textbf{Memory Boundary Transitions}: Both write and read operations require careful translation between WebAssembly linear memory and native memory spaces, testing the memory safety mechanisms implemented in the host functions and validating the pointer translation logic.

\textbf{Error Handling Pathways}: The routine exercises the complete error lifting and lowering pipeline, ensuring that \acrshort{i2c} protocol errors are correctly propagated from hardware through the host implementation to the guest application without loss of semantic information.

\textbf{Bidirectional Communication}: The sequence tests both host-to-guest parameter passing (addresses, lengths) and guest-to-host data transfer (message buffers), validating the complete communication infrastructure including memory allocation and data marshalling.

\textbf{Hardware Integration}: The actual \acrshort{i2c} communication with the target device ensures that the entire software stack correctly interfaces with real hardware, validating the embedded HAL integration and confirming that the abstraction layers do not interfere with proper \acrshort{i2c} protocol implementation.

\subsection{Hardware Configuration}
\label{subsec:eval-setup-hw}

The experimental testbed consists of a Raspberry Pi acting as the \acrshort{i2c} controller, connected to an Arduino Uno serving as the \acrshort{i2c} target.

\textbf{\acrshort{i2c} Controller Configuration:}
\begin{itemize}
    \item Board: \textit{Raspberry Pi 5}~\cite{rpi5_specs}
    \item Architecture: \textit{ARM64}
    \item Operating System: \textit{Raspberry Pi OS (reference 2024-11-19)}~\cite{pi_os}
\end{itemize}

\textbf{\acrshort{i2c} Target Configuration:}
\begin{itemize}
    \item Board: \textit{Arduino Uno R3 (ATmega328P)}~\cite{uno_specs}
    \item \acrshort{i2c} Address: \textit{0x09}
    \item Serial Interface: \textit{USB serial for correctness verification (disabled during performance tests)}
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\textwidth]{images/HW_config.png}
	\caption{Hardware connection diagram. SDA: Pi pin 3 to Arduino A4; SCL: Pi pin 5 to Arduino A5. Ground cable connection was omitted for simplicity of the diagram, but uses Pi pin 6 to Arduino GND.}
	\label{fig:hw-connection}
\end{figure}

\subsection{Arduino Firmware Implementation}
\label{subsec:eval-setup-fw}

Two firmware versions were developed for different evaluation phases:

\subsubsection{Correctness Verification Firmware}
This firmware implements echo functionality for debugging. All \acrshort{i2c} transactions are logged via USB serial, enabling transaction verification.

\subsubsection{Performance Testing Firmware}
For performance benchmarks, an optimized firmware version was deployed that eliminates serial communication overhead. Upon receiving any \acrshort{i2c} write request, the Arduino responds with a fixed ``hello'' message (\texttt{0x68, 0x65, 0x6c, 0x6c, 0x6f}) for one subsequent read operation. This approach minimizes Arduino-side processing variability and keeps extra overhead to a minimum.

\subsection{Methodology}
\label{subsec:eval-setup-bench}

The evaluation follows a three-phase methodology to ensure correctness and robust measurement of latency and memory utilization.

\subsubsection{Phase 1: Correctness Verification}
Prior to profiling, functional correctness is verified by executing ping-pong operations across all implementations and confirming successful \acrshort{i2c} transactions via Arduino serial monitor output.

\subsubsection{Phase 2: Performance Measurement}
Performance evaluation employs \textbf{Criterion.rs}, a statistical benchmarking framework that provides automatic outlier detection, distribution plotting, calculates achievable sample size prior to measurements during a warm-up phase and provides statistical insights post measurements~\cite{criterion_docs}. The intermediary tool \texttt{cargo-criterion}~\cite{cargo_criterion_docs} is an extension to Cargo and provides machine-readable JSON output of those measurements, which allows us to also perform manual analysis and visualizations using Python/Jupyter.

The benchmark is divided into three different measurements, referred to as \textbf{Groups}. Each runtime gets evaluated over 100 samples according to the group's implementation:
\begin{itemize}
    \item \textbf{Runtime Setup:} Time to initialize runtime and prepare for \acrshort{i2c} operations
    \item \textbf{Cold Execution:} A single ping-pong operation after a new runtime initialization
    \item \textbf{Hot Execution:} Repeated ping-pong operations in steady state
\end{itemize}

\subsubsection{Phase 3: Memory utilization}
A single binary is built to run memory utilization profiling across all the different runtimes, using DHAT~\cite{dhat_crate}. Two profilers are initialized, measuring Runtime Setup and Guest execution. A separate binary for each runtime is compiled to analyze the resulting binary sizes.

\section{Performance Analysis: Runtime Setup}
\label{sec:eval-setup}

Runtime initialization represents a critical performance dimension, particularly for embedded devices deployed in scenarios where Time-to-First-Execution is crucial. This section analyzes the setup overhead for each runtime and discusses the implications for practical deployment scenarios.

While the native implementation is categorized under Runtime Setup, it does not involve any runtime initialization. Instead, it establishes a performance baseline by measuring the Linux \acrshort{i2c} Stack overhead for opening the \texttt{/dev/i2c-1} device file. Since the \acrshort{wasm} implementations utilize the same underlying Linux \acrshort{i2c} software stack, this baseline enables quantification of the additional overhead introduced purely by runtime instantiation when compared against the \acrshort{wasm} implementations.

Table~\ref{tab:wasm-setup} presents the initialization overhead for \acrshort{wamr} and Wasmtime implementations compared to the Native baseline. Figure~\ref{fig:wasm-setup-distribution} gives a visual representation.

\begin{table}[h]
    \centering
    \caption{Runtime Setup overhead comparison, showcasing absolute differences between implementations.}
    \label{tab:wasm-setup}
    \begin{tabular}{l|S[table-format=5.2]|S[table-format=5.2]|S[table-format=5.2]|S[table-format=6.2]@{\, ; \,}S[table-format=5.3]}
        \toprule
        \textbf{Implementation} & \textbf{Mean (\si{\micro\second})} & \textbf{Median (\si{\micro\second})} & \textbf{Std Dev (\si{\nano\second})} & \multicolumn{2}{c}{\textbf{95\% CI (\si{\micro\second})}} \\
        \midrule
        Native      & 1.9466 & 1.9483 & 10.5846 & [ 1.9445 & 1.9487 ] \\
        WAMR        & 253.1126 & 253.1301 & 258.4145 & [ 253.0613 & 253.1638 ] \\
        Wasmtime    & 19559.1592 & 19559.8473 & 11656.5225 & [ 19556.8463 & 19561.4721 ] \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/setup-distribution}
    \caption{Distribution plots, showcasing relatively stable measurements.}
    \label{fig:wasm-setup-distribution}
\end{figure}

\subsection{Analysis}
The results reveal a dramatic performance disparity between the two WebAssembly runtimes. \acrshort{wamr} achieves setup initialization in approximately \SIi{253}{\micro\second}, representing a \SIi{130}{\times} overhead compared to the native implementation. However, Wasmtime exhibits substantially higher initialization costs at \SIi{19.6}{\milli\second}, creating a just over \SIi{10000}{\times} overhead relative to the native implementation and a \SIi{77}{\times} overhead compared to the \acrshort{wamr} implementation. Figure~\ref{fig:wasm-setup-relative} gives a visualization of the dramatic differences.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/setup_bars}
    \caption{Bar chart comparing Runtime Setup overhead, showcasing the much higher Wasmtime overhead for setting up the runtime.}
    \label{fig:wasm-setup-relative}
\end{figure}

\subsection{Embedded Application Implications}
\label{subsec:setup-implications}

These setup time characteristics have profound implications for embedded deployment patterns. For example:

\textbf{Ultra Low Power:} In some cases, Ultra Low Power devices leaving their duty cycle are completely turned off, making them lose their state. Setting up a new Wasmtime instance each time would take up too much power. In some extreme scenarios, even setting up \acrshort{wamr} could be too much overhead, but it would remain feasible in cases where the benefits of WebAssembly are favored.

\textbf{Real-time Systems:} Applications requiring deterministic startup behavior within millisecond constraints would exclude Wasmtime entirely, while \acrshort{wamr}'s sub-millisecond setup remains viable for many real-time scenarios.

\textbf{Long-running Applications:} Conversely, applications with infrequent instantiation (e.g., edge computing services) can amortize Wasmtime's setup cost over extended execution periods.

\section{Performance Analysis: Ping-Pong Execution}
\label{sec:eval-execution}

With runtime initialization complete, this section examines the steady-state execution performance for \acrshort{i2c} operations, comparing cold (first-execution) and hot (repeated-execution) characteristics.

Table~\ref{tab:wasm-execution} compares execution performance between WAMR, Wasmtime, and Native for both Cold and Hot Routine Executions.

\begin{table}[h]
    \centering
    \caption{WebAssembly Execution Performance Comparison}
    \label{tab:wasm-execution}
    \begin{tabular}{c|l|S[table-format=4.2]|S[table-format=4.2]|S[table-format=4.2]|S[table-format=5.2]@{\, ; \,}S[table-format=4.3]}
        \toprule
        \textbf{Execution} & \textbf{Implementation} & \textbf{Mean (\si{\micro\second})} & \textbf{Median (\si{\micro\second})} & \textbf{Std Dev (\si{\nano\second})} & \multicolumn{2}{c}{\textbf{95\% CI (\si{\micro\second})}} \\
        \midrule
        \multirow{3}{*}{Cold}
            & Native    & 594.5275 & 594.5636 & 281.8579 & [594.4715 & 594.5834] \\
            & WAMR      & 1211.0415 & 1210.9849 & 5144.4222 & [1210.0207 & 1212.0622] \\
            & Wasmtime  & 1301.8975 & 1300.5868 & 4895.5251 & [1300.9262 & 1302.8689] \\
        \hline
        \multirow{3}{*}{Hot}
            & Native    & 589.0368 & 589.0307 & 69.9196 & [589.0230 & 589.0507] \\
            & WAMR      & 1185.4778 & 1185.8310 & 673.0608 & [1185.3442 & 1185.6113] \\
            & Wasmtime  & 1184.4430 & 1184.2941 & 522.5048 & [1184.3393 & 1184.5467] \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/execution_distribution}
    \caption{Distribution plots showcasing stability of the measurements.}
    \label{fig:wasm-execution-distribution}
\end{figure}

\subsection{Analysis}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{images/wasm-execution-rel}
    \caption{Execution Performance Comparison: Native vs \acrshort{wamr} vs Wasmtime}
    \label{fig:wasm-execution-relative}
\end{figure}

\begin{enumerate}
    \item \textbf{Convergent Steady-State Performance:} Both WAMR and Wasmtime achieve remarkably similar hot execution performance with a \SIi{2}{\times} native overhead, despite their architectural differences.
    
    \item \textbf{Cold/Hot Differences:} Minimal cold/hot differences for WAMR (\SI[round-precision=1]{2.1}{\percent} improvement), with Wasmtime showing moderate optimization benefits (\SI[round-precision=1]{9}{\percent} improvement), suggesting some caching or similar optimization effects.
    
    \item \textbf{Consistent WebAssembly Overhead:} Both implementations exhibit approximately \SIi{2}{\times} overhead compared to native execution, representing the cost of WebAssembly instruction execution and host function call marshalling.
\end{enumerate}

\subsection{Performance Variability Assessment}
\label{subsec:eval-execution-variability}

Table~\ref{tab:variability} presents Coefficient of Variation (CV) metrics to assess performance consistency across implementations. Figure~\ref{fig:variability-comparison}

\begin{table}[h]
    \centering
    \caption{Performance Variability Comparison (Coefficient of Variation)}
    \label{tab:variability}
    \begin{tabular}{lccc}
    \toprule
    \textbf{Implementation} & \textbf{Setup CV (\%)} & \textbf{Cold Exec CV (\%)} & \textbf{Hot Exec CV (\%)} \\
    \midrule
    Native       & 0.5438 & 0.0474 & 0.0119 \\
    WAMR         & 0.1021 & 0.4248 & 0.0568 \\
    Wasmtime     & 0.0596 & 0.3760 & 0.0441 \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/variability-comparison}
    \caption{Comparison of calculated Coefficient of Variation across all implementations}
    \label{fig:variability-comparison}
\end{figure}

The performance variability analysis reveals distinct consistency patterns across the three implementations. During the setup phase, the native implementation exhibits the highest variability (\SI[round-precision=2]{0.54}{\percent} CV), suggesting that direct hardware initialization is less predictable or stable, while Wasmtime demonstrates the most consistent setup behavior (\SI[round-precision=2]{0.06}{\percent} CV). This pattern reverses during cold execution, where both WebAssembly runtimes show significantly higher variability (WAMR: \SI[round-precision=2]{0.42}{\percent}, Wasmtime: \SI[round-precision=2]{0.38}{\percent}) compared to the native implementation (\SI[round-precision=3]{0.047}{\percent}). This increased variability can be attributed to the complex initialization and optimization processes within the WebAssembly runtimes during first execution. However, during hot execution, all implementations converge to low variability levels, with the native implementation achieving the highest consistency (\SI[round-precision=3]{0.012}{\percent} CV), followed by Wasmtime (\SI[round-precision=3]{0.044}{\percent}) and WAMR (\SI[round-precision=3]{0.057}{\percent}). Importantly, all Coefficient of Variation values remain well below \SI[round-precision=0]{1}{\percent}, indicating that despite relative differences between implementations, all approaches demonstrate excellent measurement consistency and predictable performance characteristics.

\section{Memory Usage Analysis}
\label{sec:eval-memory}

Memory consumption patterns provide critical insights for embedded applications with constrained resources. This section analyzes heap allocation behavior during both runtime setup and execution phases using DHAT profiling.

\subsection{Runtime Setup}
\label{subsec:memory-setup}

Table~\ref{tab:memory-setup} presents memory allocation characteristics during runtime initialization, revealing the resource requirements for each implementation approach.

\begin{table}[h]
    \centering
    \caption{Memory Usage During Runtime Setup}
    \label{tab:memory-setup}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Implementation} & \textbf{Total (bytes)} & \textbf{Peak (bytes)} & \textbf{Blocks (count)} \\
        \midrule
        Native        & 10          & 10        & 1 \\
        WAMR          & 10,124      & 10,080    & 16 \\
        Wasmtime      & 14,247,171  & 2,716,728 & 16,686 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/mem_runtime.png}
    \caption{Comparison of memory allocations during Runtime Setup on a logarithmic scale, highlighting the much higher memory consumption of Wasmtime}
    \label{fig:mem_runtime}
\end{figure}

\subsubsection{Analysis}

The memory allocation patterns during runtime initialization reveal fundamental architectural differences between the implementations. The native implementation establishes a minimal baseline with just \SIi{10}{\byte} allocated, reflecting direct hardware access without abstraction overhead.

WAMR demonstrates embedded-friendly resource consumption, requiring approximately \SIi{10}{\kilo\byte} across 16 allocation blocks. This three-order-of-magnitude increase over native remains acceptable for most embedded systems, particularly given that \SI[round-precision=1]{99.6}{\percent} of allocated memory persists throughout the runtime lifecycle—indicating efficient, stable memory management without excessive allocation churn.

Wasmtime's memory profile reflects its sophisticated execution engine architecture. While total allocations reach \SI{14.25}{\mega\byte} during initialization, the runtime maintains only \SI{2.72}{\mega\byte} at peak usage. This \SI[round-precision=1]{81}{\percent} temporary allocation ratio reveals intensive memory operations during JIT compilation and module optimization. The \num[round-precision=0]{16686} allocation blocks (over \SIi{1000}{\times} more than WAMR) further illustrate the complexity of component model instantiation and type system initialization. Most importantly, Wasmtime's peak memory usage crosses the RAM limitations of both the ESP32-C3 (\SIi{400}{\kilo\byte}) and the Nucleo (\SIi{256}{\kilo\byte}) of the Portability Criteria from Table~\ref{tab:portability_criteria_specs}. Further optimization strategies were not researched, so will not be discussed.

These patterns directly impact deployment feasibility: WAMR's \SIi{10}{\kilo\byte} footprint fits comfortably within typical embedded constraints (even sub-MB microcontrollers), while Wasmtime's multi-megabyte requirements restrict it to more capable embedded Linux platforms. The correlation between memory complexity and setup time (\SIi{77}{\times} difference) suggests that memory allocation overhead contributes significantly to initialization latency.

\subsection{Execution}

Table~\ref{tab:memory-execution} presents memory allocation characteristics during the execution of the Ping-Pong routine, revealing the resource requirements for each implementation approach.

\begin{table}[H]
    \centering
    \caption{Memory Usage During Ping-Pong Execution}
    \label{tab:memory-execution}
    \begin{tabular}{lrrr}
        \toprule
        \textbf{Implementation} & \textbf{Total (bytes)} & \textbf{Peak (bytes)} & \textbf{Blocks (count)} \\
        \midrule
        Native        & 16   & 16  & 1 \\
        WAMR          & 327  & 311 & 6 \\
        Wasmtime      & 416  & 347 & 10 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/mem_execution_all.png}
    \caption{Comparison of memory allocations during execution of the PingPong functionality, with both \acrshort{wasm} runtimes showcasing similar peak memory requirements.}
    \label{fig:mem_pingpong}
\end{figure}

\subsubsection{Analysis}

Both runtimes demonstrate remarkable efficiency: WAMR requires \SIi{327}{\byte} across 6 allocations, while Wasmtime uses \SIi{416}{\byte} across 10 allocations --- a negligible \SIi{89}{\byte} difference despite their architectural disparities. Compared to the \SIi{16}{\byte} native baseline, this represents approximately \SIrange[round-precision=0]{20}{26}{\times} overhead respectively, primarily attributable to WASI interface marshalling and guest-host communication buffers.

The minimal peak-to-total allocation differences (WAMR: \SI[round-precision=0]{5}{\percent}, Wasmtime: \SI[round-precision=0]{17}{\percent}) indicate stable execution without memory leaks or excessive temporary allocations. This efficiency validates both runtimes for long-running embedded applications where thousands of \acrshort{i2c} operations must execute within constrained memory budgets.

Critically, these results demonstrate that the substantial initialization costs --- particularly Wasmtime's \SI{14.25}{\mega\byte} --- do not translate to proportional execution overhead. Once initialized, both runtimes operate within hundreds of bytes, making the initialization cost a one-time investment that can be amortized across the application lifetime.

\subsection{Binary Size}
\label{subsec:binary-size}

Binary size represents a critical deployment consideration for embedded systems, directly impacting flash memory requirements and distribution costs. This analysis examines the compilation footprint of each implementation variant, including both standard and optimized builds that target minimal binary size through \texttt{no\_std} compilation strategies.

Table~\ref{tab:binary-sizes} presents the binary size characteristics across all implementations, including both standard and optimized variants. The optimized variants employ aggressive size reduction techniques, including Link Time Optimization (LTO), optimization level \texttt{-Oz} (optimize for size), and \texttt{no\_std} compilation strategies that eliminate the standard library overhead. For every host implementation, the \texttt{aarch64-unknown-linux-musl} target was used. Musl is a lightweight implementation of the C standard library, specifically designed for embedded environments~\cite{musl}. It uses static linking out of the box, making sure the binary files include everything they need to execute successfully.

\begin{table}[H]
    \centering
    \caption{Binary Size Comparison Across Implementation Variants}
    \label{tab:binary-sizes}
    \begin{tabular}{lrrr}
    \toprule
    \textbf{Implementation} & \textbf{Standard Build (MB)} & \textbf{Optimized Build (KB)} & \textbf{Size Reduction (\%)} \\
    \midrule
    Native              & 7.23  & 348   & 95.2 \\
    WAMR                & 10.44 & 660   & 93.7 \\
    Wasmtime            & 12.20 & 3,609 & 70.4 \\
    \bottomrule
    \end{tabular}
\end{table}

The standard builds include full runtime initialization capabilities with debugging support and standard library linking, while optimized builds embed the guest module directly within the host binary and apply comprehensive size reduction optimizations. For the WAMR implementation, the Preview 1 guest module contributes \SIi{38}{\kilo\byte} in standard builds and \SIi{4.8}{\kilo\byte} in optimized builds. The Wasmtime Preview 2 component remains at \SIi{16.2}{\kilo\byte} on its own, as \texttt{no\_std} compilation is not compatible with runtime binding generation tools providing Preview 2 support. Manual interference could solve that issue, but it defeats the desire for the enhanced developer experience.

\textbf{Standard Build Analysis:} The unoptimized builds reveal the base overhead of each runtime architecture. Wasmtime's \SIi{12.2}{\mega\byte} footprint reflects its sophisticated compilation infrastructure and component model support, representing a \SI[round-precision=1]{69}{\percent} increase over the native baseline. WAMR's \SIi{10.4}{\mega\byte} binary demonstrates a more modest \SI[round-precision=1]{44}{\percent} overhead, aligning with its embedded-focused design philosophy that prioritizes resource efficiency over feature completeness. Either way, without optimizations or careful design without the standard library, these sizes are too large for constrained embedded devices.

\textbf{Optimized Build Analysis:} The size reduction potential through aggressive optimization varies significantly across implementations. Native implementations achieve the most dramatic compression (\SI[round-precision=1]{95.2}{\percent} reduction to \SIi{348}{\kilo\byte}), demonstrating that direct hardware access patterns are highly amenable to dead code elimination and static linking optimizations. WAMR follows closely with \SI[round-precision=1]{93.7}{\percent} reduction to \SIi{660}{\kilo\byte}, indicating that its architecture remains compatible with embedded optimization strategies.

Wasmtime's more modest \SI[round-precision=1]{70.4}{\percent} reduction to \SI{3.609}{\mega\byte} reflects the inherent complexity of the component model and WIT binding infrastructure, which resists aggressive optimization due to dynamic type system requirements. This minimum achievable footprint significantly exceeds the flash memory constraints of the Nucleo F412ZG (\SIi{1}{\mega\byte} flash), defined in the Portability Criteria.

\textbf{Embedded Systems Deployment Implications:} The binary size analysis reveals a clear architectural trade-off between feature sophistication and deployment flexibility. WAMR's optimized \SIi{660}{\kilo\byte} footprint remains viable for moderately constrained embedded systems, while still providing WebAssembly isolation and portability benefits. Wasmtime's \SI{3.609}{\mega\byte} minimum requirement restricts itself to deployment on more capable embedded platforms with sufficient flash storage.

The dramatic size reduction potential (\SI[round-precision=1]{93.7}{\percent} for WAMR) demonstrates that embedded WebAssembly deployments can achieve reasonable footprints when unnecessary debugging infrastructure and standard library dependencies are eliminated. However, these optimizations require careful consideration of development workflow impacts, as debugging capabilities are significantly reduced in size-optimized builds.

\section*{Reproducibility}
All experimental code and benchmarks are available at: \url{https://github.com/idlab-discover/wamr-wasi-i2c}. The repository includes automated setup scripts enabling complete reproduction with the \texttt{Just} tool.